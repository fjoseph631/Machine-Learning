{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P1 HW2 AI",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjoseph631/Machine-Learning/blob/master/P1_HW2_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0nI1sX2CBSA",
        "colab_type": "text"
      },
      "source": [
        "##Imports\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-cjKKeV85uC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "bf4e6d7e-3102-49c4-e23e-b9dc7bc7ac1b"
      },
      "source": [
        "from skimage import measure\n",
        "from skimage import filters\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy\n",
        "from scipy.ndimage import gaussian_filter\n",
        "from sklearn.preprocessing import binarize\n",
        "import cv2\n",
        "from scipy.sparse.csgraph import connected_components\n",
        "\n",
        "import math\n",
        "from scipy.sparse import csr_matrix\n",
        "from keras.datasets import mnist\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.utils import to_categorical\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tS0cQ0pICFh7",
        "colab_type": "text"
      },
      "source": [
        "##Load in MNIST set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAn2wXp7nHNl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e6140b09-36da-45fa-f352-40e08c2fcd45"
      },
      "source": [
        "\n",
        "\n",
        "(train_images_original, train_labels_original), (test_images_original, test_labels_original) = mnist.load_data()\n",
        "train_images = train_images_original.reshape((60000, 784))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images_original.reshape((10000, 784))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels_original)\n",
        "test_labels = to_categorical(test_labels_original)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vb8iqZgvCPpH",
        "colab_type": "text"
      },
      "source": [
        "## Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdojbfrXVOh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getWidthAndHeight(image):\n",
        "  \n",
        "  yMax= -1\n",
        "  yMin= 256\n",
        "  xMin = 256\n",
        "  xMax = -1\n",
        "  a=image\n",
        "  for i in range(28):\n",
        "    for j in range(28):\n",
        "      if(a[i][j]>=0):\n",
        "        yMax= max(j,yMax)\n",
        "        xMin= min(i,xMin)\n",
        "        yMin= min(j,yMin)\n",
        "        xMax= max(i,xMax)\n",
        "  width = (yMax- yMin) /28\n",
        "  height = (xMax- xMin) /28\n",
        "  return width,height\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JBlpJ6km1jc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getComponents(image):\n",
        "      #x = binarize(image.reshape(1,-1)) \n",
        "      #a_output = np.ravel(x)\n",
        "      n_components = connected_components(csgraph=csr_matrix(np.reshape(image,(28,28))), directed=False, return_labels=False)\n",
        "      return n_components"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhqAeckHCZCJ",
        "colab_type": "text"
      },
      "source": [
        "## Calculating Features "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "104Zq2mYzo7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "images = []\n",
        "for i in range(len(train_images)):\n",
        "  z,y=(getWidthAndHeight(np.reshape(train_images[i],(28,28))))\n",
        "  x= getComponents(train_images[i])\n",
        "  train_images[i].flatten()\n",
        "  a=[z,y,x]\n",
        "  a=np.array(a)\n",
        "  images.append(np.concatenate([train_images[i],a]))\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCq2NQutCxhs",
        "colab_type": "text"
      },
      "source": [
        "##Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_NuYkr6KoVU",
        "colab_type": "code",
        "outputId": "32cad8ba-9858-47b2-826f-0a981a488df5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#keras.preprocessing.sequence.pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre', value=0.0)\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(10, activation='softmax', input_shape=(787,)))\n",
        "#network.add(layers.Dense(10, activation='softmax', input_shape=(784,)))\n",
        "\n",
        "#network.summary()\n",
        "network.compile(optimizer='adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "epochs = 25\n",
        "\n",
        "\n",
        "a = (keras.preprocessing.sequence.pad_sequences(train_images, maxlen=787, dtype='float32', padding='post', truncating='post', value=0.0))\n",
        "b = (keras.preprocessing.sequence.pad_sequences(test_images, maxlen=787, dtype='float32', padding='post', truncating='post', value=0.0))\n",
        "\n",
        "history = network.fit(np.array(images),\n",
        "                      train_labels, \n",
        "                      epochs=epochs, \n",
        "                      batch_size=128, \n",
        "                      validation_data=(np.array(b)\n",
        ", test_labels))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/25\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.6777 - acc: 0.8319 - val_loss: 0.4538 - val_acc: 0.8751\n",
            "Epoch 2/25\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.3552 - acc: 0.9029 - val_loss: 0.4355 - val_acc: 0.8703\n",
            "Epoch 3/25\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.3135 - acc: 0.9127 - val_loss: 0.4259 - val_acc: 0.8716\n",
            "Epoch 4/25\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.2947 - acc: 0.9173 - val_loss: 0.4080 - val_acc: 0.8791\n",
            "Epoch 5/25\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.2834 - acc: 0.9205 - val_loss: 0.4273 - val_acc: 0.8701\n",
            "Epoch 6/25\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.2761 - acc: 0.9224 - val_loss: 0.4085 - val_acc: 0.8774\n",
            "Epoch 7/25\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.2707 - acc: 0.9238 - val_loss: 0.3884 - val_acc: 0.8828\n",
            "Epoch 8/25\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.2664 - acc: 0.9245 - val_loss: 0.3909 - val_acc: 0.8828\n",
            "Epoch 9/25\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.2629 - acc: 0.9259 - val_loss: 0.4161 - val_acc: 0.8751\n",
            "Epoch 10/25\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.2598 - acc: 0.9264 - val_loss: 0.3919 - val_acc: 0.8827\n",
            "Epoch 11/25\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.2575 - acc: 0.9273 - val_loss: 0.4072 - val_acc: 0.8762\n",
            "Epoch 12/25\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.2552 - acc: 0.9281 - val_loss: 0.4122 - val_acc: 0.8735\n",
            "Epoch 13/25\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.2534 - acc: 0.9291 - val_loss: 0.3991 - val_acc: 0.8796\n",
            "Epoch 14/25\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.2519 - acc: 0.9296 - val_loss: 0.3925 - val_acc: 0.8825\n",
            "Epoch 15/25\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.2507 - acc: 0.9298 - val_loss: 0.3890 - val_acc: 0.8839\n",
            "Epoch 16/25\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.2492 - acc: 0.9304 - val_loss: 0.3888 - val_acc: 0.8824\n",
            "Epoch 17/25\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.2478 - acc: 0.9310 - val_loss: 0.4054 - val_acc: 0.8786\n",
            "Epoch 18/25\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.2470 - acc: 0.9312 - val_loss: 0.3961 - val_acc: 0.8818\n",
            "Epoch 19/25\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.2461 - acc: 0.9314 - val_loss: 0.3935 - val_acc: 0.8819\n",
            "Epoch 20/25\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.2451 - acc: 0.9317 - val_loss: 0.4044 - val_acc: 0.8794\n",
            "Epoch 21/25\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.2442 - acc: 0.9319 - val_loss: 0.4028 - val_acc: 0.8795\n",
            "Epoch 22/25\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.2433 - acc: 0.9326 - val_loss: 0.3740 - val_acc: 0.8892\n",
            "Epoch 23/25\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.2424 - acc: 0.9326 - val_loss: 0.3986 - val_acc: 0.8816\n",
            "Epoch 24/25\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.2413 - acc: 0.9329 - val_loss: 0.3575 - val_acc: 0.8937\n",
            "Epoch 25/25\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.2411 - acc: 0.9332 - val_loss: 0.3777 - val_acc: 0.8880\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}