{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P1 HW2 AI",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjoseph631/Machine-Learning/blob/master/P1_HW2_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0nI1sX2CBSA",
        "colab_type": "text"
      },
      "source": [
        "##Imports\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-cjKKeV85uC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage import measure\n",
        "from skimage import filters\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy\n",
        "from scipy.ndimage import gaussian_filter\n",
        "from sklearn.preprocessing import binarize\n",
        "import cv2\n",
        "from scipy.sparse.csgraph import connected_components\n",
        "\n",
        "import math\n",
        "from scipy.sparse import csr_matrix\n",
        "from keras.datasets import mnist\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.utils import to_categorical\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tS0cQ0pICFh7",
        "colab_type": "text"
      },
      "source": [
        "##Load in MNIST set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAn2wXp7nHNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "(train_images_original, train_labels_original), (test_images_original, test_labels_original) = mnist.load_data()\n",
        "train_images = train_images_original.reshape((60000, 784))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images_original.reshape((10000, 784))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels_original)\n",
        "test_labels = to_categorical(test_labels_original)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vb8iqZgvCPpH",
        "colab_type": "text"
      },
      "source": [
        "## Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdojbfrXVOh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getWidthAndHeight(image):\n",
        "  \n",
        "  yMax= -1\n",
        "  yMin= 256\n",
        "  xMin = 256\n",
        "  xMax = -1\n",
        "  a=image\n",
        "  for i in range(28):\n",
        "    for j in range(28):\n",
        "      if(a[i][j]>=0):\n",
        "        yMax= max(j,yMax)\n",
        "        xMin= min(i,xMin)\n",
        "        yMin= min(j,yMin)\n",
        "        xMax= max(i,xMax)\n",
        "  width = (yMax- yMin) /28\n",
        "  height = (xMax- xMin) /28\n",
        "  return width,height\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JBlpJ6km1jc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getComponents(image):\n",
        "      #x = binarize(image.reshape(1,-1)) \n",
        "      #a_output = np.ravel(x)\n",
        "      n_components = connected_components(csgraph=csr_matrix(np.reshape(image,(28,28))), directed=False, return_labels=False)\n",
        "      return n_components"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhqAeckHCZCJ",
        "colab_type": "text"
      },
      "source": [
        "## Calculating Features "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "104Zq2mYzo7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "images = []\n",
        "for i in range(len(train_images)):\n",
        "  z,y=(getWidthAndHeight(np.reshape(train_images[i],(28,28))))\n",
        "  x= getComponents(train_images[i])\n",
        "  train_images[i].flatten()\n",
        "  a=[z,y,x]\n",
        "  a=np.array(a)\n",
        "  images.append(np.concatenate([train_images[i],a]))\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyzPJ9Clc5ci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train = []\n",
        "test=[]\n",
        "\n",
        "for i in range(len(test_images)):\n",
        "  #zed = np.append(test_images[i],[0,0,0])\n",
        "  #test\n",
        "  test_images[i].flatten()\n",
        "  a=[0,0,0]\n",
        "  a=np.array(a)\n",
        "  test.append(np.concatenate([test_images[i],a]))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCq2NQutCxhs",
        "colab_type": "text"
      },
      "source": [
        "##Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_NuYkr6KoVU",
        "colab_type": "code",
        "outputId": "bae83ef7-75bf-4f24-f1cf-66b014f15482",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "#keras.preprocessing.sequence.pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre', value=0.0)\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(10, activation='softmax', input_shape=(787,)))\n",
        "#network.add(layers.Dense(10, activation='softmax', input_shape=(784,)))\n",
        "\n",
        "#network.summary()\n",
        "network.compile(optimizer='adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "epochs = 6\n",
        "\n",
        "\n",
        "a = (keras.preprocessing.sequence.pad_sequences(train_images, maxlen=787, dtype='int32', padding='post', truncating='post', value=0.0))\n",
        "b = (keras.preprocessing.sequence.pad_sequences(test_images, maxlen=787, dtype='int32', padding='post', truncating='post', value=0.0))\n",
        "\n",
        "history = network.fit(np.array(images),\n",
        "                      train_labels, \n",
        "                      epochs=epochs, \n",
        "                      batch_size=128, \n",
        "                      validation_data=(np.array(b)\n",
        ", test_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/6\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.6738 - acc: 0.8317 - val_loss: 2.1469 - val_acc: 0.2594\n",
            "Epoch 2/6\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.3543 - acc: 0.9038 - val_loss: 2.1287 - val_acc: 0.2583\n",
            "Epoch 3/6\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.3131 - acc: 0.9125 - val_loss: 2.1202 - val_acc: 0.2611\n",
            "Epoch 4/6\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 0.2945 - acc: 0.9178 - val_loss: 2.1125 - val_acc: 0.2581\n",
            "Epoch 5/6\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.2835 - acc: 0.9203 - val_loss: 2.1073 - val_acc: 0.2568\n",
            "Epoch 6/6\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.2760 - acc: 0.9221 - val_loss: 2.1031 - val_acc: 0.2559\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}